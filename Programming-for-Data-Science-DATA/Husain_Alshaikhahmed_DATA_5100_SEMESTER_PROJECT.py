{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgmheN9BDN-6"
   },
   "outputs": [],
   "source": [
    "# this is the collection_data.py\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# This class is going to prepare the data into a suitable format\n",
    "# Credit due to : https://www.kaggle.com/datasets/grassknoted/asl-alphabet\n",
    "def dataset_preparation(\n",
    "        # this is my local path\n",
    "        dataset_path=r'E:\\Documents\\King Of The Software Engineers\\ML\\DATA 5100 Programming for Data Science\\Final '\n",
    "                     r'Porject'):\n",
    "    dataset_info = {\n",
    "        'number_of_images': 0,\n",
    "        'classes': [],\n",
    "        'train_split': 0.8,\n",
    "        'validation_split': 0.2\n",
    "    }\n",
    "\n",
    "    # Iterate dataset directory\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "\n",
    "        # Counts the number of image files in a directory with the given extensions\n",
    "\n",
    "        dataset_info['number_of_images'] += len([f for f in files if f.endswith(('.jpg', '.png', '.jpeg'))])\n",
    "        # # Capture only top directories\n",
    "        if not dataset_info['classes'] and dirs:\n",
    "            dataset_info['classes'] = dirs\n",
    "\n",
    "    return dataset_info\n",
    "\n",
    "\n",
    "def main():\n",
    "    # my local path\n",
    "    DATASET_PATH = (r'E:\\Documents\\King Of The Software Engineers\\ML\\DATA 5100 Programming for Data Science\\Final '\n",
    "                    r'Porject\\archive\\asl_alphabet_train\\asl_alphabet_train')\n",
    "    # Gather and preprocess data\n",
    "    dataset_information = dataset_preparation(DATASET_PATH)\n",
    "    print(\"Data Collection and Preprocessing Summary:\")\n",
    "    print(f\"Number of Imges: {dataset_information['number_of_images']}\")\n",
    "    print(f\"Available classes: {dataset_information['classes']}\")\n",
    "    print(f\" The split: {dataset_information['train_split'] * 100}%\")\n",
    "    print(f\"The validation split: {dataset_information['validation_split'] * 100}%\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# This is the model_training.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "class SignModel:\n",
    "    def __init__(self, input_shape=(64, 64, 3),\n",
    "                 num_classes=29):  # This response the available class, A-Z, nothing, space, and delete\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.model = self.develop_model()\n",
    "\n",
    "    def develop_model(self):\n",
    "        # determine the input layer shape\n",
    "        model = tf.keras.Sequential([\n",
    "            layers.Input(shape=self.input_shape),  # shrink the images\n",
    "            layers.Conv2D(32, 3, activation='relu'),\n",
    "\n",
    "            layers.MaxPooling2D(),  # reduce more of the dimensions\n",
    "            layers.Conv2D(64, 3, activation='relu'),\n",
    "\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Conv2D(64, 3, activation='relu'),\n",
    "\n",
    "            layers.MaxPooling2D(),\n",
    "            layers.Flatten(),\n",
    "\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dense(self.num_classes, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Dataset path\n",
    "    DATASET_PATH = r'E:\\Documents\\King Of The Software Engineers\\ML\\DATA 5100 Programming for Data Science\\Final Porject\\archive\\asl_alphabet_train\\asl_alphabet_train'\n",
    "    MODEL_SAVE_PATH = os.path.join(os.path.dirname(DATASET_PATH), 'best_sign_language_model.keras')\n",
    "\n",
    "    # Data augmentation and preprocessing\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    # Display Class options\n",
    "    print(f\"The options classes: {sorted(os.listdir(DATASET_PATH))}\")\n",
    "\n",
    "    # Prepare data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        DATASET_PATH,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        DATASET_PATH,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    # Initialize the model\n",
    "    sign_model = SignModel(num_classes=len(os.listdir(DATASET_PATH)))\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        MODEL_SAVE_PATH,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # traning the model\n",
    "    history = sign_model.model.fit(\n",
    "        train_generator,\n",
    "        validation_data=validation_generator,\n",
    "        epochs=50,\n",
    "        callbacks=[checkpoint, early_stopping]\n",
    "    )\n",
    "\n",
    "    # display evaluation\n",
    "    final_accuracy = history.history['accuracy'][-1]\n",
    "    final_val_accuracy = history.history['val_accuracy'][-1]\n",
    "    print(f\"\\nModel training is now complete!\")\n",
    "    print(f\"The training accuracy: {final_accuracy:.4f}\")\n",
    "    print(f\"The validation accuracy: {final_val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ],
   "metadata": {
    "id": "zDUfmPGTDSLQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# this is the GUI.py\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from PIL import Image, ImageTk\n",
    "import cv2\n",
    "import os\n",
    "from tkinter import PhotoImage\n",
    "\n",
    "\n",
    "class SignLanguageInterpreter:\n",
    "    def __init__(self):\n",
    "\n",
    "        # # Initialize the Tkinter\n",
    "        self.root = tk.Tk()\n",
    "\n",
    "        # Set the GUI size, width and height\n",
    "        self.root.geometry('1000x800')\n",
    "        # Set the GUI title\n",
    "        self.root.title(\"Sign Language Interpreter\")\n",
    "        # path for sign language images\n",
    "        # It is stored in my local machine\n",
    "        # We can also use Kaggle API however I find this more convenient\n",
    "        self.images_path = (r'E:\\Documents\\King Of The Software Engineers\\ML\\DATA 5100 Programming for Data '\n",
    "                            r'Science\\Final Porject\\archive\\asl_alphabet_train\\asl_alphabet_train')\n",
    "\n",
    "        self.make_widgets()\n",
    "        # Change the background color\n",
    "        self.root.configure(bg=\"lightgreen\")\n",
    "        # Tinker logo\n",
    "        # Credit  due to https://www.flaticon.com/search?word=Sign%20Language\n",
    "        self.root.iconphoto(True, PhotoImage(file=\"sign-language.png\"))\n",
    "\n",
    "    def make_widgets(self):\n",
    "\n",
    "        self.text_input = tk.Entry(self.root, width=50, font=('Comic Sans MS', 14))\n",
    "        self.input_label = tk.Label(self.root, text=\"Translate Text:\", font=('Comic Sans MS', 14))\n",
    "\n",
    "        self.text_input.pack(pady=11)\n",
    "        self.input_label.pack(pady=11)\n",
    "\n",
    "        # Translate button, assigning job to the buttons\n",
    "        self.btn_translate = (tk.Button\n",
    "            (\n",
    "            self.root,\n",
    "            text=\"Translate\",\n",
    "            command=self.translation,\n",
    "            font=('Comic Sans MS', 14)\n",
    "        ))\n",
    "        self.btn_translate.pack(pady=11)\n",
    "\n",
    "        self.image_frame = tk.Frame(self.root)\n",
    "        self.image_frame.pack(pady=22, expand=True, fill='both')\n",
    "\n",
    "    def translation(self):\n",
    "        # Clear the cash images\n",
    "        for widget in self.image_frame.winfo_children():\n",
    "            widget.destroy()\n",
    "\n",
    "        text = self.text_input.get().upper()\n",
    "        row = tk.Frame(self.image_frame)\n",
    "        row.pack()\n",
    "\n",
    "        for i, c in enumerate(text):\n",
    "            if c == c.isspace():\n",
    "\n",
    "                image_path = os.path.join(self.images_path, 'space')\n",
    "            elif c.isalpha():\n",
    "\n",
    "                image_path = os.path.join(self.images_path, c)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            # Find the first images\n",
    "            try:\n",
    "                image_file = os.listdir(image_path)[0]\n",
    "                image_path = os.path.join(image_path, image_file)\n",
    "\n",
    "                # Load the images\n",
    "                img = Image.open(image_path)\n",
    "                # adjust for display\n",
    "                img = img.resize((95, 95))\n",
    "                img = ImageTk.PhotoImage(img)\n",
    "\n",
    "                # Make the label then display the images\n",
    "                lbl = tk.Label(row, image=img)\n",
    "                lbl.image = img\n",
    "                lbl.pack(side=tk.LEFT, padx=5)\n",
    "\n",
    "                # make a new row for every 5 characters\n",
    "                if (i + 1) % 5 == 0:\n",
    "                    row = tk.Frame(self.image_frame)\n",
    "                    row.pack()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to load image for the {c}: {e}\")\n",
    "\n",
    "    def start(self):\n",
    "        self.root.mainloop()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = SignLanguageInterpreter()\n",
    "    app.start()\n"
   ],
   "metadata": {
    "id": "kBBQtslrDnWB"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
